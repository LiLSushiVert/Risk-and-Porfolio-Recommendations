import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

data = pd.read_csv(r"C:\Users\dangb\PycharmProjects\PythonProject\Dataset\bank.csv", sep=',')

plt.figure(figsize=(10, 6))
sns.histplot(data['age'], bins=20, kde=True, color='skyblue')
plt.title("Ph√¢n b·ªë ƒë·ªô tu·ªïi kh√°ch h√†ng")
plt.xlabel("Tu·ªïi")
plt.ylabel("S·ªë l∆∞·ª£ng")
plt.grid(axis='y')
plt.tight_layout()
plt.show()

plt.figure(figsize=(8, 5))
sns.boxplot(x=data['balance'], color='lightcoral')
plt.title("Boxplot s·ªë d∆∞ t√†i kho·∫£n (balance)")
plt.xlabel("S·ªë d∆∞")
plt.grid(axis='x')
plt.tight_layout()
plt.show()

plt.figure(figsize=(12, 6))
sns.countplot(x=data['job'], order=data['job'].value_counts().index)
plt.title("Ph√¢n b·ªë ngh·ªÅ nghi·ªáp kh√°ch h√†ng")
plt.xlabel("Ngh·ªÅ nghi·ªáp")
plt.ylabel("S·ªë l∆∞·ª£ng")
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

plt.figure(figsize=(8, 5))
sns.countplot(x=data['marital'])
plt.title("Ph√¢n b·ªë t√¨nh tr·∫°ng h√¥n nh√¢n kh√°ch h√†ng")
plt.xlabel("T√¨nh tr·∫°ng h√¥n nh√¢n")
plt.ylabel("S·ªë l∆∞·ª£ng")
plt.grid(axis='y')
plt.tight_layout()
plt.show()

features = ['age', 'job', 'marital', 'education', 'balance', 'housing', 'loan']
data = data[features]

label_encoders = {}
for col in data.select_dtypes(include='object').columns:
    le = LabelEncoder()
    data[col] = le.fit_transform(data[col])
    label_encoders[col] = le
warnings.filterwarnings("ignore", category=UserWarning)

eda_data = data.copy()

conditions = [
    (data['balance'] < 0) | ((data['loan'] == 1) & (data['housing'] == 1)),
    ((data['balance'] >= 0) & (data['balance'] < 1000)),
    (data['balance'] >= 1000)
]
risk_labels = ['High', 'Medium', 'Low']
data['risk_level'] = np.select(conditions, risk_labels, default='Medium')

eda_data = data.copy()

if 'marital' in label_encoders:
    eda_data['marital_label'] = label_encoders['marital'].inverse_transform(eda_data['marital'])

plt.figure(figsize=(10,6))
sns.countplot(data=eda_data, x='marital_label', hue='risk_level', palette='Set2')
plt.title("Ph√¢n b·ªë m·ª©c ƒë·ªô r·ªßi ro theo t√¨nh tr·∫°ng h√¥n nh√¢n", fontsize=14)
plt.xlabel("T√¨nh tr·∫°ng h√¥n nh√¢n")
plt.ylabel("S·ªë l∆∞·ª£ng kh√°ch h√†ng")
plt.xticks(rotation=0)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

if 'education' in label_encoders:
    eda_data['education_label'] = label_encoders['education'].inverse_transform(eda_data['education'])

plt.figure(figsize=(10,6))
sns.countplot(data=eda_data, x='education_label', hue='risk_level', palette='Set3')
plt.title("Ph√¢n b·ªë m·ª©c ƒë·ªô r·ªßi ro theo tr√¨nh ƒë·ªô h·ªçc v·∫•n", fontsize=14)
plt.xlabel("Tr√¨nh ƒë·ªô h·ªçc v·∫•n")
plt.ylabel("S·ªë l∆∞·ª£ng kh√°ch h√†ng")
plt.xticks(rotation=0)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

plt.figure(figsize=(8,6))
numeric_cols = ['age', 'balance', 'loan', 'housing']
corr_matrix = eda_data[numeric_cols].corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("üî• Ma tr·∫≠n t∆∞∆°ng quan gi·ªØa c√°c ƒë·∫∑c tr∆∞ng s·ªë h·ªçc", fontsize=14)
plt.tight_layout()
plt.show()

plt.figure(figsize=(10,6))
sns.histplot(data=eda_data, x='age', hue='risk_level', multiple='stack', palette='Set2', bins=20)
plt.title("Ph√¢n ph·ªëi m·ª©c ƒë·ªô r·ªßi ro theo ƒë·ªô tu·ªïi", fontsize=14)
plt.xlabel("Tu·ªïi")
plt.ylabel("S·ªë l∆∞·ª£ng")
plt.grid(axis='y')
plt.tight_layout()
plt.show()

le_risk = LabelEncoder()
data['risk_level_encoded'] = le_risk.fit_transform(data['risk_level'])

X_dt = data.drop(['risk_level', 'risk_level_encoded'], axis=1)
y_dt = data['risk_level_encoded']

X_train_dt, X_test_dt, y_train_dt, y_test_dt = train_test_split(X_dt, y_dt, test_size=0.3, random_state=42)

model = DecisionTreeClassifier(max_depth=4, random_state=42)
model.fit(X_train_dt, y_train_dt)

y_pred_dt = model.predict(X_test_dt)
print("\nƒê·ªô ch√≠nh x√°c m√¥ h√¨nh Decision Tree:", accuracy_score(y_test_dt, y_pred_dt))
print("\n B√°o c√°o ph√¢n lo·∫°i (Decision Tree):\n", classification_report(y_test_dt, y_pred_dt))

cm = confusion_matrix(y_test_dt, y_pred_dt)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=le_risk.classes_, yticklabels=le_risk.classes_)
plt.title("Confusion Matrix - Decision Tree")
plt.xlabel("D·ª± ƒëo√°n")
plt.ylabel("Th·ª±c t·∫ø")
plt.show()

plt.figure(figsize=(15, 8))
plot_tree(model, feature_names=X_dt.columns, class_names=le_risk.classes_, filled=True)
plt.title("Decision Tree - Ph√¢n lo·∫°i r·ªßi ro t√†i ch√≠nh")
plt.show()

investment_mapping = {
    'High': ['Qu·ªπ ti·∫øt ki·ªám an to√†n', 'B·∫£o hi·ªÉm nh√¢n th·ªç'],
    'Medium': ['Tr√°i phi·∫øu ch√≠nh ph·ªß', 'Ch·ª©ng ch·ªâ qu·ªπ'],
    'Low': ['C·ªï phi·∫øu', 'B·∫•t ƒë·ªông s·∫£n', 'Qu·ªπ ƒë·∫ßu t∆∞ m·∫°o hi·ªÉm']
}

data['investment_suggestions'] = data['risk_level'].map(investment_mapping)
data['investment_recommendation_rulebased'] = data['investment_suggestions'].apply(lambda x: x[0])

print("\n G·ª£i √Ω ƒë·∫ßu t∆∞ (Rule-Based) - 10 kh√°ch h√†ng ƒë·∫ßu ti√™n:")
print(data[['age', 'job', 'balance', 'risk_level', 'investment_recommendation_rulebased']].head(10))

product_profiles = {
    'Qu·ªπ ti·∫øt ki·ªám an to√†n': {'age': 55, 'balance': 100, 'loan': 1, 'housing': 1},
    'B·∫£o hi·ªÉm nh√¢n th·ªç': {'age': 50, 'balance': 200, 'loan': 1, 'housing': 1},
    'Tr√°i phi·∫øu ch√≠nh ph·ªß': {'age': 40, 'balance': 500, 'loan': 0, 'housing': 1},
    'Ch·ª©ng ch·ªâ qu·ªπ': {'age': 35, 'balance': 800, 'loan': 0, 'housing': 1},
    'C·ªï phi·∫øu': {'age': 30, 'balance': 1500, 'loan': 0, 'housing': 0},
    'B·∫•t ƒë·ªông s·∫£n': {'age': 45, 'balance': 2000, 'loan': 0, 'housing': 1},
    'Qu·ªπ ƒë·∫ßu t∆∞ m·∫°o hi·ªÉm': {'age': 28, 'balance': 3000, 'loan': 0, 'housing': 0},
}

def content_based_recommendation(row):
    similarities = {}
    for product, profile in product_profiles.items():
        vec1 = np.array([row['age'], row['balance'], row['loan'], row['housing']])
        vec2 = np.array([profile['age'], profile['balance'], profile['loan'], profile['housing']])
        sim = cosine_similarity([vec1], [vec2])[0][0]
        similarities[product] = sim
    return max(similarities, key=similarities.get)

data['investment_recommendation_content'] = data.apply(content_based_recommendation, axis=1)

print("\n G·ª£i √Ω ƒë·∫ßu t∆∞ (Content-Based) - 10 kh√°ch h√†ng ƒë·∫ßu ti√™n:")
print(data[['age', 'balance', 'risk_level', 'investment_recommendation_content']].head(10))

weights = {
    'rule_based': 0.8,
    'content_based': 0.9
}

data['score_fusion'] = data.apply(lambda row: {
    row['investment_recommendation_rulebased']: weights['rule_based'],
    row['investment_recommendation_content']: weights['content_based']
}, axis=1)

data['final_recommendation'] = data['score_fusion'].apply(lambda scores: max(scores, key=scores.get))

print("\n G·ª£i √Ω ƒë·∫ßu t∆∞ (Score-Level Fusion) - 10 kh√°ch h√†ng ƒë·∫ßu ti√™n:")
print(data[['age', 'balance', 'risk_level', 'final_recommendation']].head(10))

data[['age', 'balance', 'risk_level', 'final_recommendation']].to_excel('goi_y_dau_tu_score_level_fusion.xlsx', index=False)
print("\n K·∫øt qu·∫£ Score-Level Fusion ƒë√£ l∆∞u v√†o file: goi_y_dau_tu_score_level_fusion.xlsx")

data.to_csv("output_final_recommendations.csv", index=False)
print("\n ƒê√£ l∆∞u file k·∫øt qu·∫£ v√†o 'output_final_recommendations.csv'")

def classify_risk_level(age, balance, loan, housing):
    if balance < 0 or (loan == 1 and housing == 1):
        return 'High'
    elif 0 <= balance < 1000:
        return 'Medium'
    else:
        return 'Low'

def get_rule_based_recommendation(risk_level):
    return investment_mapping.get(risk_level, ["Kh√¥ng x√°c ƒë·ªãnh"])[0]

def get_content_based_recommendation(customer):
    similarities = {}
    for product, profile in product_profiles.items():
        vec1 = np.array([customer['age'], customer['balance'], customer['loan'], customer['housing']])
        vec2 = np.array([profile['age'], profile['balance'], profile['loan'], profile['housing']])
        sim = cosine_similarity([vec1], [vec2])[0][0]
        similarities[product] = sim
    return max(similarities, key=similarities.get)

report_dict = classification_report(y_test_dt, y_pred_dt, target_names=le_risk.classes_, output_dict=True)
df_report = pd.DataFrame(report_dict).transpose()
df_metrics = df_report.loc[le_risk.classes_, ['precision', 'recall', 'f1-score']]

plt.figure(figsize=(10,6))
df_metrics.plot(kind='bar')
plt.title("Bi·ªÉu ƒë·ªì Precision - Recall - F1-score theo t·ª´ng l·ªõp r·ªßi ro (Decision Tree)")
plt.ylabel("Score")
plt.ylim(0, 1.1)
plt.xticks(rotation=0)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

plt.figure(figsize=(6,5))
sns.countplot(data=data, x='risk_level', hue='risk_level', palette='Set2', legend=False)
plt.title("Ph√¢n b·ªë c√°c m·ª©c ƒë·ªô r·ªßi ro")
plt.xlabel("M·ª©c ƒë·ªô r·ªßi ro")
plt.ylabel("S·ªë l∆∞·ª£ng kh√°ch h√†ng")
plt.grid(axis='y')
plt.tight_layout()
plt.show()

fusion_recommendation_counts = data['final_recommendation'].value_counts()
plt.figure(figsize=(6,6))
fusion_recommendation_counts.plot.pie(
    autopct='%1.1f%%',
    startangle=90,
    colors=sns.color_palette('Set3')
)
plt.title("T·ª∑ l·ªá c√°c danh m·ª•c ƒë·∫ßu t∆∞ ƒë∆∞·ª£c g·ª£i √Ω (Score-Level Fusion)")
plt.ylabel("")
plt.tight_layout()
plt.show()

X_rf = data.drop(['risk_level', 'risk_level_encoded', 'investment_suggestions',
                  'investment_recommendation_rulebased', 'investment_recommendation_content',
                  'score_fusion', 'final_recommendation'], axis=1)
y_rf = data['risk_level_encoded']

X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf, y_rf, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train_rf = scaler.fit_transform(X_train_rf)
X_test_rf = scaler.transform(X_test_rf)
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train_rf, y_train_rf)

y_pred_rf = rf.predict(X_test_rf)

y_pred_label_rf = le_risk.inverse_transform(y_pred_rf)

print("\n[Classification Report - Random Forest]:")
print(classification_report(y_test_rf, y_pred_rf, target_names=le_risk.classes_))

df_result_rf = pd.DataFrame(X_test_rf, columns=X_rf.columns)
df_result_rf['RiskLevel'] = y_pred_label_rf

df_result_rf['InvestmentSuggestion'] = df_result_rf['RiskLevel'].map(lambda x: investment_mapping[x][0])

print("\n[Danh s√°ch g·ª£i √Ω ƒë·∫ßu t∆∞ cho 10 kh√°ch h√†ng ƒë·∫ßu ti√™n (Random Forest)]:")
print(df_result_rf[['RiskLevel', 'InvestmentSuggestion']].head(10))

df_result_rf[['RiskLevel', 'InvestmentSuggestion']].to_excel('goi_y_dau_tu_model2.xlsx', index=False)
print("\n K·∫øt qu·∫£ Random Forest ƒë√£ l∆∞u v√†o file: goi_y_dau_tu_model2.xlsx")

plt.figure(figsize=(6, 4))
sns.heatmap(confusion_matrix(y_test_rf, y_pred_rf), annot=True, fmt='d', cmap='Blues',
            xticklabels=le_risk.classes_, yticklabels=le_risk.classes_)
plt.title("Confusion Matrix - Random Forest")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

plt.figure(figsize=(6, 4))
sns.countplot(x=y_pred_label_rf, hue=y_pred_label_rf, palette='Set2', legend=False)
plt.title("Ph√¢n b·ªë m·ª©c ƒë·ªô r·ªßi ro d·ª± ƒëo√°n (Random Forest)")
plt.xlabel("Risk Level")
plt.ylabel("S·ªë l∆∞·ª£ng kh√°ch h√†ng")
plt.grid(axis='y')
plt.tight_layout()
plt.show()

report_dict_rf = classification_report(y_test_rf, y_pred_rf, target_names=le_risk.classes_, output_dict=True)
df_report_rf = pd.DataFrame(report_dict_rf).transpose()
df_metrics_rf = df_report_rf.loc[le_risk.classes_, ['precision', 'recall', 'f1-score']]

plt.figure(figsize=(8, 5))
df_metrics_rf.plot(kind='bar')
plt.title("Precision - Recall - F1-score theo t·ª´ng l·ªõp (Random Forest)")
plt.ylabel("Score")
plt.ylim(0, 1.1)
plt.xticks(rotation=0)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

investment_counts_rf = df_result_rf['InvestmentSuggestion'].value_counts()

plt.figure(figsize=(6, 6))
investment_counts_rf.plot.pie(autopct='%1.1f%%', startangle=90, colors=sns.color_palette('Set3'))
plt.title("T·ª∑ l·ªá c√°c danh m·ª•c ƒë·∫ßu t∆∞ ƒë∆∞·ª£c g·ª£i √Ω (Random Forest)")
plt.ylabel("")
plt.tight_layout()
plt.show()

print("\n Nh·∫≠p d·ªØ li·ªáu kh√°ch h√†ng m·ªõi ƒë·ªÉ ƒë√°nh gi√° r·ªßi ro v√† g·ª£i √Ω ƒë·∫ßu t∆∞:")
age = int(input("Tu·ªïi: "))
job = input("Ngh·ªÅ nghi·ªáp (v√≠ d·ª•: admin, technician, blue-collar, etc.): ").lower()
marital = input("T√¨nh tr·∫°ng h√¥n nh√¢n (single/married/divorced): ").lower()
education = input("Tr√¨nh ƒë·ªô h·ªçc v·∫•n (primary/secondary/tertiary/unknown): ").lower()
balance = int(input("S·ªë d∆∞ t√†i kho·∫£n: "))
housing = input("C√≥ vay nh√†? (yes/no): ").lower()
loan = input("C√≥ vay c√° nh√¢n? (yes/no): ").lower()

new_customer = pd.DataFrame([{
    'age': age,
    'job': job,
    'marital': marital,
    'education': education,
    'balance': balance,
    'housing': housing,
    'loan': loan
}])

for col in ['job', 'marital', 'education', 'housing', 'loan']:
    if col in label_encoders:
        known_classes = set(label_encoders[col].classes_)
        new_customer[col] = new_customer[col].apply(lambda x: x if x in known_classes else 'unknown')
        new_customer[col] = label_encoders[col].transform(new_customer[col])

X_new = new_customer[X_dt.columns]

predicted_risk_encoded = model.predict(X_new)[0]
predicted_risk = le_risk.inverse_transform([predicted_risk_encoded])[0]

loan_val = int(new_customer['loan'].values[0])
housing_val = int(new_customer['housing'].values[0])
risk_level_rulebased = classify_risk_level(age, balance, loan_val, housing_val)

investment_recommendation_rulebased = get_rule_based_recommendation(risk_level_rulebased)

investment_recommendation_content = get_content_based_recommendation({
    'age': age,
    'balance': balance,
    'loan': loan_val,
    'housing': housing_val
})

score_fusion = {}
score_fusion[investment_recommendation_rulebased] = score_fusion.get(investment_recommendation_rulebased, 0) + weights['rule_based']
score_fusion[investment_recommendation_content] = score_fusion.get(investment_recommendation_content, 0) + weights['content_based']

final_recommendation = max(score_fusion, key=score_fusion.get)

print("\n K·∫æT QU·∫¢ ƒê√ÅNH GI√Å KH√ÅCH H√ÄNG M·ªöI:")
print(f"Rule-Based Risk Level: {risk_level_rulebased}")
print(f"Decision Tree Risk Prediction: {predicted_risk}")
print(f"G·ª£i √Ω ƒë·∫ßu t∆∞ (Rule-Based): {investment_recommendation_rulebased}")
print(f"G·ª£i √Ω ƒë·∫ßu t∆∞ (Content-Based): {investment_recommendation_content}")
print("\nƒêi·ªÉm s·ªë c·ªßa c√°c g·ª£i √Ω (Score-Level Fusion):", score_fusion)
print("G·ª¢I √ù CU·ªêI C√ôNG (Score-Level Fusion):", final_recommendation)

